name: Grid E2E (Fargate → Tests → Destroy)

on:
  push:
    branches: [ main ]
  workflow_dispatch:

env:
  AWS_REGION: us-east-1
  IAC_DIR: iac
  TF_STATE_KEY: selforge-grid/main/terraform.tfstate

jobs:
  e2e:
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS (OIDC → assume role)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Who am I
        run: aws sts get-caller-identity

      - name: Show Terraform files used by runner
        run: |
          set -e
          echo "Listing ${{ env.IAC_DIR }}:"
          ls -la "${{ env.IAC_DIR }}"
          echo "----- main.tf (head) -----"
          sed -n '1,120p' "${{ env.IAC_DIR }}/main.tf" || true
          echo "----- main.tf (tail) -----"
          sed -n '121,999p' "${{ env.IAC_DIR }}/main.tf" || true

      - name: Ensure remote state infra (S3/Dynamo)
        shell: bash
        env:
          TF_STATE_BUCKET: ${{ secrets.TF_STATE_BUCKET }}
          TF_STATE_REGION: ${{ secrets.TF_STATE_REGION }}
          TF_STATE_LOCK_TABLE: ${{ secrets.TF_STATE_LOCK_TABLE }}
        run: |
          set -euo pipefail
          if ! aws s3api head-bucket --bucket "${TF_STATE_BUCKET}" 2>/dev/null; then
            if [ "${TF_STATE_REGION}" = "${AWS_REGION}" ]; then
              aws s3api create-bucket --bucket "${TF_STATE_BUCKET}" --region "${TF_STATE_REGION}"
            else
              aws s3api create-bucket --bucket "${TF_STATE_BUCKET}" --region "${TF_STATE_REGION}" \
                --create-bucket-configuration LocationConstraint="${TF_STATE_REGION}"
            fi
            aws s3api put-bucket-versioning --bucket "${TF_STATE_BUCKET}" --versioning-configuration Status=Enabled
          fi
          if ! aws dynamodb describe-table --table-name "${TF_STATE_LOCK_TABLE}" >/dev/null 2>&1; then
            aws dynamodb create-table \
              --table-name "${TF_STATE_LOCK_TABLE}" \
              --attribute-definitions AttributeName=LockID,AttributeType=S \
              --key-schema AttributeName=LockID,KeyType=HASH \
              --billing-mode PAY_PER_REQUEST \
              --region "${TF_STATE_REGION}"
            aws dynamodb wait table-exists --table-name "${TF_STATE_LOCK_TABLE}" --region "${TF_STATE_REGION}"
          fi

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3

      - name: Terraform Init
        working-directory: ${{ env.IAC_DIR }}
        env:
          TF_VAR_name_prefix: selenium-fargate
        run: |
          terraform init -reconfigure \
            -backend-config="bucket=${{ secrets.TF_STATE_BUCKET }}" \
            -backend-config="region=${{ secrets.TF_STATE_REGION }}" \
            -backend-config="dynamodb_table=${{ secrets.TF_STATE_LOCK_TABLE }}" \
            -backend-config="key=${{ env.TF_STATE_KEY }}"

      - name: Terraform Plan (fail if EC2 appears)
        working-directory: ${{ env.IAC_DIR }}
        shell: bash
        run: |
          set -e
          terraform plan -no-color | tee plan.txt
          if grep -q 'aws_instance\.' plan.txt; then
            echo "❌ Detected aws_instance in plan (old EC2 stack). Ensure iac/main.tf is the Fargate version."
            exit 1
          fi

      - name: Terraform Apply (Fargate Grid)
        working-directory: ${{ env.IAC_DIR }}
        run: terraform apply -auto-approve

      - name: Capture Outputs (tolerant)
        id: tfout
        working-directory: ${{ env.IAC_DIR }}
        shell: bash
        run: |
          set -e
          GRID_URL="$(terraform output -raw grid_url)"
          NOVNC_URL="$(terraform output -raw novnc_url 2>/dev/null || true)"
          echo "grid_url=${GRID_URL}"   >> $GITHUB_OUTPUT
          [ -n "$NOVNC_URL" ] && echo "novnc_url=${NOVNC_URL}" >> $GITHUB_OUTPUT || true
          echo "Grid URL: $GRID_URL"
          [ -n "$NOVNC_URL" ] && echo "noVNC URL: $NOVNC_URL" || echo "noVNC URL not defined"

      - name: Wait for ALB:80 and /status
        env:
          GRID_URL: ${{ steps.tfout.outputs.grid_url }}
        shell: bash
        run: |
          set -e
          URL="${GRID_URL%/}"
          HOST="${URL#http://}"; HOST="${HOST#https://}"; HOST="${HOST%%/*}"; HOST="${HOST%%:*}"
          echo "Probing $HOST:80 ..."
          for i in $(seq 1 120); do
            if timeout 2 bash -lc "cat </dev/null > /dev/tcp/$HOST/80" 2>/dev/null; then
              echo "Port 80 is open."
              break
            fi
            echo "Port 80 not open yet... ($i/120)"
            sleep 5
          done
          echo "Waiting for /status to be healthy..."
          for i in $(seq 1 120); do
            if curl -fsS "$URL/status" | jq -e '.value.ready == true' >/dev/null 2>&1; then
              echo "Selenium is ready."
              exit 0
            fi
            echo "Not ready yet... ($i/120)"
            sleep 5
          done
          echo "Grid did not become ready in time."
          curl -v "$URL/status" || true
          exit 1

      - name: Set up JDK
        uses: actions/setup-java@v4
        with:
          distribution: temurin
          java-version: "21"

      - name: Maven Tests (point to Fargate Grid)
        env:
          GRID_URL: ${{ steps.tfout.outputs.grid_url }}
        run: |
          mvn -B -Dgrid.url="$GRID_URL" -Dallure.results.directory=target/allure-results test
          echo "---- After tests, results tree ----"
          ls -la target || true
          ls -la target/allure-results || true

      # --- Allure HTML build --------------------------------------------------

      - name: Build Allure HTML
        if: always()
        run: |
          if [ ! -d target/allure-results ] || [ -z "$(ls -A target/allure-results 2>/dev/null)" ]; then
            echo "❌ No Allure results in target/allure-results; cannot build report."
            exit 1
          fi
          mvn -B -Dallure.results.directory=target/allure-results io.qameta.allure:allure-maven:report

      # --- NEW: Extract Allure metrics → CSV for QuickSight -------------------

      - name: Extract Allure metrics CSVs
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          REPORT_DIR="target/site/allure-maven"
          RESULTS_DIR="target/allure-results"

          # test-level file
          OUT_TESTS="allure-tests.csv"
          echo "run_id,test_name,status,start,stop,duration_ms,package,suite,testClass,fullName" > "$OUT_TESTS"

          get_label() {
            local file="$1" key="$2"
            jq -r --arg k "$key" '
              (.labels // []) | map(select(.name==$k)) | .[0].value // ""
            ' "$file"
          }

          shopt -s nullglob
          for f in "$RESULTS_DIR"/*-result.json; do
            name=$(jq -r '.name // ""' "$f")
            status=$(jq -r '.status // ""' "$f")
            start=$(jq -r '.start // 0' "$f")
            stop=$(jq -r '.stop // 0' "$f")
            duration=$(( stop>start ? stop-start : 0 ))
            package=$(get_label "$f" "package")
            suite=$(get_label "$f" "suite")
            testClass=$(get_label "$f" "testClass")
            fullName=$(jq -r '.fullName // ""' "$f")
            # very simple CSV escaping (values are usually clean)
            echo "${GITHUB_RUN_ID},\"$name\",$status,$start,$stop,$duration,\"$package\",\"$suite\",\"$testClass\",\"$fullName\"" >> "$OUT_TESTS"
          done

          # run summary file (from report widgets)
          OUT_SUM="allure-summary.csv"
          W_SUM="$REPORT_DIR/widgets/summary.json"
          echo "run_id,total,passed,failed,broken,skipped,unknown" > "$OUT_SUM"
          if [ -f "$W_SUM" ]; then
            jq -r --arg rid "$GITHUB_RUN_ID" '
              [$rid,
               (.statistic.total // 0),
               (.statistic.passed // 0),
               (.statistic.failed // 0),
               (.statistic.broken // 0),
               (.statistic.skipped // 0),
               (.statistic.unknown // 0)
              ] | @csv
            ' "$W_SUM" >> "$OUT_SUM"
          else
            echo "$GITHUB_RUN_ID,0,0,0,0,0,0" >> "$OUT_SUM"
          fi

      - name: Upload metrics CSVs to S3 for QuickSight
        if: always()
        env:
          BUCKET: ${{ secrets.REPORTS_BUCKET }}
          RUN_PREFIX: grid/allure/${{ github.run_id }}-${{ github.run_attempt }}
        shell: bash
        run: |
          set -e
          if [ -z "${BUCKET}" ]; then
            echo "ℹ️ REPORTS_BUCKET not set; skipping CSV publish."
            exit 0
          fi
          DATA_PREFIX="grid/allure/datasets"
          aws s3 cp allure-tests.csv   "s3://${BUCKET}/${DATA_PREFIX}/${RUN_PREFIX}-tests.csv"
          aws s3 cp allure-summary.csv "s3://${BUCKET}/${DATA_PREFIX}/${RUN_PREFIX}-summary.csv"
          aws s3 cp allure-tests.csv   "s3://${BUCKET}/${DATA_PREFIX}/latest-tests.csv"
          aws s3 cp allure-summary.csv "s3://${BUCKET}/${DATA_PREFIX}/latest-summary.csv"

          # QS manifests (one-time path; runner overwrites)
          cat > manifest-tests.json <<EOF
          {
            "fileLocations": [{"URIs": ["s3://${BUCKET}/${DATA_PREFIX}/latest-tests.csv"]}],
            "globalUploadSettings": {"format":"CSV","delimiter":",","textqualifier":"\"","containsHeader":true}
          }
          EOF
          cat > manifest-summary.json <<EOF
          {
            "fileLocations": [{"URIs": ["s3://${BUCKET}/${DATA_PREFIX}/latest-summary.csv"]}],
            "globalUploadSettings": {"format":"CSV","delimiter":",","textqualifier":"\"","containsHeader":true}
          }
          EOF
          aws s3 cp manifest-tests.json   "s3://${BUCKET}/${DATA_PREFIX}/manifest-tests.json"
          aws s3 cp manifest-summary.json "s3://${BUCKET}/${DATA_PREFIX}/manifest-summary.json"

          {
            echo "## QuickSight datasets"
            echo ""
            echo "- Tests manifest:   s3://${BUCKET}/${DATA_PREFIX}/manifest-tests.json"
            echo "- Summary manifest: s3://${BUCKET}/${DATA_PREFIX}/manifest-summary.json"
          } >> "$GITHUB_STEP_SUMMARY"

      # --- Publish Allure HTML to S3 (versioned + latest) ---------------------

      - name: Publish Allure to S3 (versioned + latest)
        if: always()
        env:
          BUCKET: ${{ secrets.REPORTS_BUCKET }}
          RUN_PREFIX: grid/allure/${{ github.run_id }}-${{ github.run_attempt }}
          REGION: ${{ env.AWS_REGION }}
        shell: bash
        run: |
          set -e
          if [ -z "${BUCKET}" ]; then
            echo "ℹ️ REPORTS_BUCKET not set; skipping S3 publish."
            exit 0
          fi

          SRC="target/site/allure-maven"
          if [ ! -d "$SRC" ]; then
            echo "❌ Allure report folder not found: $SRC"
            echo "Did tests write to target/allure-results?"
            exit 1
          fi

          aws s3 sync "$SRC" "s3://$BUCKET/$RUN_PREFIX" \
            --delete --cache-control "no-cache" --metadata-directive REPLACE
          aws s3 sync "$SRC" "s3://$BUCKET/grid/allure/latest" \
            --delete --cache-control "no-cache" --metadata-directive REPLACE

          VER_S3="s3://$BUCKET/$RUN_PREFIX/index.html"
          LATEST_S3="s3://$BUCKET/grid/allure/latest/index.html"
          VER_URL="https://${BUCKET}.s3.${REGION}.amazonaws.com/${RUN_PREFIX}/index.html"
          LATEST_URL="https://${BUCKET}.s3.${REGION}.amazonaws.com/grid/allure/latest/index.html"

          echo "Versioned (S3):   $VER_S3"
          echo "Latest   (S3):   $LATEST_S3"
          echo "Versioned (HTTPS): $VER_URL"
          echo "Latest   (HTTPS): $LATEST_URL"

          {
            echo "## Allure report"
            echo ""
            echo "- Versioned (HTTPS): ${VER_URL}"
            echo "- Latest (HTTPS): ${LATEST_URL}"
            echo ""
            echo "<sub>S3 URIs: ${VER_S3} / ${LATEST_S3}</sub>"
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Upload Allure HTML as artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: allure-html
          path: target/site/allure-maven
          if-no-files-found: warn
          retention-days: 7

      - name: Always destroy infra
        if: always()
        working-directory: ${{ env.IAC_DIR }}
        run: terraform destroy -auto-approve
